{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covidForecast.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pfbnk7iZuTOVu3ZlSZrv0rnc9MDXy9nc",
      "authorship_tag": "ABX9TyPmJRXHhzoWRvJ3qnJDYN39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajhilins/covid-data-analysis/blob/main/covidForecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxTFHhJ-PnRd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.model_selection import RepeatedKFold,cross_val_score\n",
        "import altair as alt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcHWGBQuPp2h"
      },
      "source": [
        "#Covid-19 Forecast in Indiana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSesFNcwkN1o"
      },
      "source": [
        "The goal of this project is to predict the number of confirmed cases in the days ahead of us using regression. I will be using data gathered by Johns Hopkins that is based on the number of confirmed cases so far. I decided to limit my area of interest to the counties of Indiana."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi8Enan7QBap"
      },
      "source": [
        "###Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEOGsJtT_5y"
      },
      "source": [
        "The data consists of 11 attributes excluding the time series data.\n",
        "\n",
        "\n",
        "*   UID: uinique id\n",
        "*   iso2: country identifier\n",
        "*   iso3: country identifier\n",
        "*   code3: country identifier\n",
        "*   FIPS: unique id for counties in US\n",
        "*   Admin2: county name\n",
        "*   Province_State: state name\n",
        "*   Country_region: country name\n",
        "*   Lat: latitude\n",
        "*   Long_: longitude\n",
        "*   Combined_Key: county, state, country combination\n",
        "*   The other attributes are confirmed cases on that date.\n",
        "\n",
        "I am going to filter out all of the attributes aside from the confirmed cases and the Admin2 attribute for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3KkzZ9RPvVl"
      },
      "source": [
        "#the data was acquired from https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
        "myData = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
        "\n",
        "#acquired from http://www.stats.indiana.edu/population/popTotals/2017_cntyest.asp\n",
        "countyPop = pd.read_csv(\"indianaCountyPopulation.csv\")\n",
        "#filtering out data not from indiana\n",
        "myData = myData.loc[myData[\"Province_State\"] == \"Indiana\"]\n",
        "#lets filter out irrelevant location data since we are focused on counties in indiana\n",
        "myData = myData.drop(columns=[\"UID\",\"iso2\",\"iso3\",\"code3\",\"FIPS\",\"Province_State\",\"Country_Region\",\"Lat\",\"Long_\",\"Combined_Key\"])\n",
        "#transforming data for time series analysis\n",
        "counties = myData.Admin2.values\n",
        "transposedData = myData.loc[myData[\"Admin2\"]==\"Adams\"].T\n",
        "for county in counties:\n",
        "  transposedData = pd.concat([transposedData, myData.loc[myData[\"Admin2\"]==county].T], axis=1)\n",
        "myData = transposedData.T.drop_duplicates().T\n",
        "\n",
        "#cleaning up indices and removing extraneous data\n",
        "myData = myData.drop(myData.index[0])\n",
        "counties = np.delete(counties,[92,93])\n",
        "myData = myData.iloc[:,0:92]\n",
        "myData.columns = counties\n",
        "\n",
        "#normalizing population data\n",
        "for index,county in enumerate(counties):\n",
        "    for j in range(0,len(myData[\"Adams\"])):\n",
        "      myData[county][j] = (myData[county][j]/countyPop.iat[index,1])*1000\n",
        "\n",
        "#dropping all data before 3/5 since its the day before the first confirmed case\n",
        "myData = myData.drop(myData.index[0:43])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQC3u0vzV1k6"
      },
      "source": [
        "#Visualization\n",
        "\n",
        "This was going to be an interactive plot, but currently google colab does not support matplotlibs interactive plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmMuKWv9VyYg"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "for county in counties:\n",
        "  ax.plot(myData[county])\n",
        "ax.legend(counties,ncol=4,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "fig.subplots_adjust(right=0.55)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Number of Confirmed Cases by County in Indiana Per Day\")\n",
        "plt.xlabel(\"Date Confirmed\")\n",
        "plt.ylabel(\"Confirmed Cases(Normalized by Pop.)\")\n",
        "ax.xaxis.set_major_locator(ticker.MaxNLocator(8))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGLkcimWf3b_"
      },
      "source": [
        "###Modelling\n",
        "\n",
        "Since most of our data appears to be linear although we know that is not the case in a pandemic, I will first be modelling using a simple linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf5hCvZrwFye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f467846-d264-4f91-ef77-1690946d858b"
      },
      "source": [
        "print()\n",
        "numberOfDays = np.arange(1,len(myData[\"Adams\"])+1)\n",
        "myData['numberOfDays'] = numberOfDays"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtV9ZHti5N1Q"
      },
      "source": [
        "####Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQZoEM8RgRP0"
      },
      "source": [
        "def linearModel(county):\n",
        "  n = len(myData[county])\n",
        "  X = np.array(myData[\"numberOfDays\"].values)\n",
        "  X = X.reshape(-1,1)\n",
        "  y = np.array(myData[county].values)\n",
        "\n",
        "\n",
        "  # Split the data into training/testing sets\n",
        "  X_train = X[:-20]\n",
        "  X_test = X[-20:]\n",
        "  y_train = y[:-20]\n",
        "  y_test = y[-20:]\n",
        "\n",
        "  # Create linear regression object\n",
        "  lm = linear_model.LinearRegression()\n",
        "\n",
        "  # Train the model using the training sets\n",
        "  lm.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions using the testing set\n",
        "  y_pred = lm.predict(X_test)\n",
        "\n",
        "  # The mean squared error\n",
        "  print('Mean squared error: {}'.format(mean_squared_error(y_test, y_pred)))\n",
        "  # The coefficient of determination: 1 is perfect prediction\n",
        "  print('Coefficient of determination: {}'.format(r2_score(y_test, y_pred)))\n",
        "  # predict ten days in advance\n",
        "  for x in range(1,11):\n",
        "    # prediction\n",
        "    print('Predicted: {}'.format(lm.predict(np.array([n+x]).reshape(-1,1))))\n",
        "\n",
        "  # Plot outputs\n",
        "  #plt.scatter(X_test, y_test,  color='black')\n",
        "  #plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
        "  #plt.xticks(())\n",
        "  #plt.yticks(())\n",
        "  #plt.show()\n",
        "\n",
        "\n",
        "\n",
        "for county in counties:\n",
        "  linearModel(county)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGye88qW47oa"
      },
      "source": [
        "After reviewing the erratic mean squared error(which tells us how close our regression line is to the points) and r-squared which is more beneficial because we scaled the data, we can see that the linear model just isnt cutting it. Even though on the inital analysis it looked as though the data had linear trends it is definetly not linear. Lets see if scaling the data to have a mean 0 and variance of 1 changes anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_qc617Ge3j6"
      },
      "source": [
        "def ridgeRegression(county):\n",
        "  n = len(myData[county])\n",
        "  X = np.array(myData[\"numberOfDays\"].values)\n",
        "  X = X.reshape(-1,1)\n",
        "  y = np.array(myData[county].values)\n",
        "\n",
        "  # Create ridge regression object\n",
        "  rm = Ridge()\n",
        "\n",
        "  # Train the model using the training sets\n",
        "  rm.fit(X,y)\n",
        "\n",
        "  # KFold for cross validation\n",
        "  cv = RepeatedKFold(n_splits=10,n_repeats=3,random_state=5)\n",
        "\n",
        "  # Eval of model performance\n",
        "  scores = cross_val_score(rm, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
        "  print('Scores: {}'.format(scores))\n",
        "\n",
        "  for x in range(1,11):\n",
        "    print('Predicted: {}'.format(rm.predict(np.array([n+x]).reshape(-1,1))))\n",
        "\n",
        "\n",
        "\n",
        "  # Plot outputs\n",
        "  #plt.scatter(X, y,  color='black')\n",
        "  #plt.plot(X, rm.predict(X), color='blue', linewidth=3)\n",
        "  #plt.xticks(())\n",
        "  #plt.yticks(())\n",
        "  #plt.show()\n",
        "\n",
        "\n",
        "\n",
        "for county in counties:\n",
        "  ridgeRegression(county)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pqkkBPSZEcD"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "The Covid19 outbreak is difficult to use a general model for because of the widely varying circumstances that every region has. This model is not good at predicting cases because it cannot take into account the other extremely important factors such as infection rate, immunity rate, fatality rate and recovery rate. The models generated here for each county seem to be underfit because of these additional factors the dataset did not contain. With all that being said these models function well due to the fact that the number of cases continues to climb, when the number of cases ceases to grow and the line stagnates the models will begin to perform worse.\n",
        "\n",
        "##Predictions\n",
        "For the predictions of each county we can see a variety of things happening, the counties that are larger we can easily see the sharp upturn in cases, the smaller the county size the more gradual the slope. Meaning the larger the county is the faster the spread is which makes sense."
      ]
    }
  ]
}